# OptiMDS
A LLM and multi-objective genetic algorithm framework to optimize the readability of medical discharge papers.


> ‚ö†Ô∏è **Notice**  
> This project is currently under review for publication. Please do not copy, reproduce, or redistribute any part of the code or dataset without explicit permission.
> This repo currently contains only one source code. I will be updating the entire code once the paper is accepted in the journal.

# üß† Readability Optimization for Medical Summaries using LLaMA 3.1 and NSGA-II

This repository contains a two-stage framework to improve the **readability** of medical discharge summaries generated by large language models (LLMs), while preserving clinical accuracy. The approach combines **abstractive summarization** using the **LLaMA 3.1 Instruct model** with **multi-objective optimization** via **NSGA-II**.

---

## üîç Project Overview

- **Summarization Module**: Uses the LLaMA 3.1 Instruct model (via Hugging Face) to generate a high-quality paragraph-format summary from medical discharge papers.
- **Optimization Module**: Applies NSGA-II to optimize:
  - ‚úÖ Readability (minimize Flesch-Kincaid Grade Level - FKGL)
  - ‚úÖ Semantic fidelity (minimize the number of word replacements)

Two optimization strategies are implemented:
- `NSGA_wordnet.py`: Uses WordNet-based synonyms
- `NSGA_word2vec.py`: Uses Word2Vec-based semantic similarity

---

## üì¶ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/the-pika/OptiMDS.git
   cd OptiMDS

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
  
üí° Note: Ensure you have a Hugging Face token set up for LLaMA model access.
